# openshift 4.14 baremetal场景 安装 nginx operator 并使用

在openshift上，除了默认的router/haproxy，还有其他的方案可以作为ingress。比如openshift认证过的nginx operator，我们今天就来试试。

- https://www.nginx.com/blog/getting-started-nginx-ingress-operator-red-hat-openshift/
- https://kubernetes.github.io/ingress-nginx/deploy/baremetal/

# nginx operator

- https://github.com/nginxinc/nginx-ingress-helm-operator
- https://github.com/nginxinc/nginx-ingress-helm-operator/blob/main/docs/openshift-installation.md

![](imgs/2024-03-08-14-03-20.png)


```bash

# 用operator hub来装nginx operator就可以。
# 然后需要加上权限(好像不用，以后试试，看创建controller instance的时候，有配置，创建rbac)

# https://github.com/nginxinc/nginx-ingress-helm-operator/blob/main/docs/openshift-installation.md
wget -O nginx.scc.yaml https://raw.githubusercontent.com/nginxinc/nginx-ingress-helm-operator/v2.1.2/resources/scc.yaml

oc apply -f nginx.scc.yaml
# securitycontextconstraints.security.openshift.io/nginx-ingress-admin created

```

![](imgs/2024-03-08-14-54-38.png)

到此，我们分析一下我们都创建了什么，接下来我们要干什么

```bash

oc get NginxIngress -A
# NAMESPACE       NAME                  AGE
# nginx-ingress   nginxingress-sample   56m

# 首先，我们看看创建的pod
oc get pod -n nginx-ingress
# NAME                                                            READY   STATUS    RESTARTS   AGE
# nginx-ingress-operator-controller-manager-6d8cbd487d-4rp6m      2/2     Running   0          166m
# nginxingress-sample-nginx-ingress-controller-5ddd56f675-7g5k7   1/1     Running   0          53m

oc get pod/nginxingress-sample-nginx-ingress-controller-5ddd56f675-7g5k7 -o json -n nginx-ingress | jq .spec | grep -i host

# 结果是没有关于host的任何配置信息
# 说明，nginx是用很特别的方式，把流量引入自己身上的。

oc get svc -n nginx-ingress
# NAME                                                        TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE
# nginx-ingress-operator-controller-manager-metrics-service   ClusterIP      172.22.43.63    <none>        8443/TCP                     18h
# nginxingress-sample-nginx-ingress-controller                LoadBalancer   172.22.145.65   <pending>     80:32758/TCP,443:31566/TCP   55m

```

到这里，我们知道了，openshift/k8s 上面的nginx operator，需要依赖外部的load balancer来导入流量，如果是云服务的话，会自动对接，但是我们是baremetal的场景，那么就必须搞一个metalLB来充当这个load balancer了

- https://github.com/kubernetes/ingress-nginx/blob/main/docs/deploy/baremetal.md

![](imgs/2024-03-08-16-02-14.png)

# metalLB

openshift 官方文档就有metalLB的手册，照着做就可以啦。

- https://docs.openshift.com/container-platform/4.14/networking/metallb/about-metallb.html

![](imgs/2024-03-08-16-05-50.png)

安装完毕以后，我们需要激活 MetalLB 

![](imgs/2024-03-08-17-14-36.png)

然后我们配置一个地址空间

![](imgs/2024-03-08-17-18-59.png)

![](imgs/2024-03-08-17-22-10.png)

然后配置二层的地址广播，注意，在这里，我们有2个可选项，一个是bgp，一个是L2，bgp需要上游路由器支持，一般企业场景不太方便，我们一般用L2，但是这要保证各个节点之间二层可达。

![](imgs/2024-03-08-17-30-38.png)

![](imgs/2024-03-08-17-31-13.png)

# nginx operator, continue

我们配置的metalLB是不能自动分配IP地址的，这是为了方便我们后面的dns配置，作者认为，在实际生产场景，应该也是不自动分配为好。

我们更新一下nginx的配置，让nginx向metalLB申请一个IP地址。

![](imgs/2024-03-08-17-40-11.png)

![](imgs/2024-03-08-17-40-39.png)


## app try

好了，我们接下来就配置一个应用，看看效果吧。

```bash

cat << EOF > ${BASE_DIR}/data/install/nginx-ingress.yaml
---
kind: Deployment
apiVersion: apps/v1
metadata:
  name: web-demo
  namespace: llm-demo
  labels:
    app: web-demo
    app.kubernetes.io/component: web-demo
    app.kubernetes.io/instance: web-demo
    app.kubernetes.io/name: web-demo
    app.kubernetes.io/part-of: web-demo
    app.openshift.io/runtime: nodejs
    app.openshift.io/runtime-namespace: llm-demo
spec:
  replicas: 1
  selector:
    matchLabels:
      app: web-demo
  template:
    metadata:
      labels:
        app: web-demo
        deployment: web-demo
    spec:
      containers:
        - name: web-demo
          image: quay.io/wangzheng422/qimgs:web-demo-v01
          ports:
            - containerPort: 8080
              protocol: TCP

---
kind: Service
apiVersion: v1
metadata:
  name: web-demo
  namespace: llm-demo
  labels:
    app: web-demo
    app.kubernetes.io/component: web-demo
    app.kubernetes.io/instance: web-demo
    app.kubernetes.io/name: web-demo
    app.kubernetes.io/part-of: web-demo
    app.openshift.io/runtime-version: web-demo-v01
spec:
  ports:
    - name: 8080-tcp
      protocol: TCP
      port: 8080
      targetPort: 8080
  selector:
    app: web-demo
    deployment: web-demo

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-demo-wzh
spec:
  rules:
  - host: nginx-demo.wzhlab.top
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web-demo
            port:
              number: 8080
  ingressClassName: nginx
EOF

oc create -f ${BASE_DIR}/data/install/nginx-ingress.yaml -n llm-demo

# oc delete -f ${BASE_DIR}/data/install/nginx-ingress.yaml -n llm-demo

```

goto to see the result:

http://nginx-demo.wzhlab.top/

![](imgs/2024-03-08-20-56-42.png)


## 原理分析

我们分析一下metalLB的原理，以及和nginx互动的关系。

```bash
oc get svc -n nginx-ingress
# NAME                                                        TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE
# nginx-ingress-operator-controller-manager-metrics-service   ClusterIP      172.22.43.63    <none>        8443/TCP                     20h
# nginxingress-sample-nginx-ingress-controller                LoadBalancer   172.22.145.65   172.21.6.41   80:32758/TCP,443:31566/TCP   166m

# 我们探究一下metalLB原理。发现是nft里面有规则，做了DNAT

iptables -L -v -n -t nat
# Chain PREROUTING (policy ACCEPT 0 packets, 0 bytes)
#  pkts bytes target     prot opt in     out     source               destination
#  2037  125K OVN-KUBE-ETP  all  --  *      *       0.0.0.0/0            0.0.0.0/0
#  2037  125K OVN-KUBE-EXTERNALIP  all  --  *      *       0.0.0.0/0            0.0.0.0/0
#  2037  125K OVN-KUBE-NODEPORT  all  --  *      *       0.0.0.0/0            0.0.0.0/0

# Chain INPUT (policy ACCEPT 0 packets, 0 bytes)
#  pkts bytes target     prot opt in     out     source               destination

# Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes)
#  pkts bytes target     prot opt in     out     source               destination
# 32647 1974K OVN-KUBE-EXTERNALIP  all  --  *      *       0.0.0.0/0            0.0.0.0/0
# 32647 1974K OVN-KUBE-NODEPORT  all  --  *      *       0.0.0.0/0            0.0.0.0/0
# 32647 1974K OVN-KUBE-ITP  all  --  *      *       0.0.0.0/0            0.0.0.0/0

# Chain POSTROUTING (policy ACCEPT 0 packets, 0 bytes)
#  pkts bytes target     prot opt in     out     source               destination
# 32647 1974K OVN-KUBE-EGRESS-IP-MULTI-NIC  all  --  *      *       0.0.0.0/0            0.0.0.0/0
# 32647 1974K OVN-KUBE-EGRESS-SVC  all  --  *      *       0.0.0.0/0            0.0.0.0/0
# 30580 1835K OVN-KUBE-SNAT-MGMTPORT  all  --  *      ovn-k8s-mp0  0.0.0.0/0            0.0.0.0/0

# Chain KUBE-KUBELET-CANARY (0 references)
#  pkts bytes target     prot opt in     out     source               destination

# Chain OVN-KUBE-EGRESS-IP-MULTI-NIC (1 references)
#  pkts bytes target     prot opt in     out     source               destination

# Chain OVN-KUBE-EGRESS-SVC (1 references)
#  pkts bytes target     prot opt in     out     source               destination
#     0     0 RETURN     all  --  *      *       0.0.0.0/0            0.0.0.0/0            mark match 0x3f0 /* DoNotSNAT */

# Chain OVN-KUBE-ETP (1 references)
#  pkts bytes target     prot opt in     out     source               destination
#     0     0 DNAT       tcp  --  *      *       0.0.0.0/0            172.21.6.41          tcp dpt:443 to:169.254.169.3:31566
#     0     0 DNAT       tcp  --  *      *       0.0.0.0/0            172.21.6.41          tcp dpt:80 to:169.254.169.3:32758

# Chain OVN-KUBE-EXTERNALIP (2 references)
#  pkts bytes target     prot opt in     out     source               destination
#     0     0 DNAT       tcp  --  *      *       0.0.0.0/0            172.21.6.41          tcp dpt:443 to:172.22.145.65:443
#     0     0 DNAT       tcp  --  *      *       0.0.0.0/0            172.21.6.41          tcp dpt:80 to:172.22.145.65:80

# Chain OVN-KUBE-ITP (1 references)
#  pkts bytes target     prot opt in     out     source               destination

# Chain OVN-KUBE-NODEPORT (2 references)
#  pkts bytes target     prot opt in     out     source               destination
#     0     0 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            ADDRTYPE match dst-type LOCAL tcp dpt:31566 to:172.22.145.65:443
#     0     0 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            ADDRTYPE match dst-type LOCAL tcp dpt:32758 to:172.22.145.65:80

# Chain OVN-KUBE-SNAT-MGMTPORT (1 references)
#  pkts bytes target     prot opt in     out     source               destination
#     0     0 RETURN     tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:31566
#     0     0 RETURN     tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:32758
# 30580 1835K SNAT       all  --  *      ovn-k8s-mp0  0.0.0.0/0            0.0.0.0/0            /* OVN SNAT to Management Port */ to:10.133.0.2

# 经过nft以后，就进入ovn了，ovn里面定义了service，然后跑到了pod上面
oc get pod -n openshift-ovn-kubernetes -o wide
# NAME                                     READY   STATUS    RESTARTS   AGE   IP            NODE             NOMINATED NODE   READINESS GATES
# ovnkube-control-plane-7648b89f9c-xzk6c   2/2     Running   9          12d   172.21.6.23   master-01-demo   <none>           <none>
# ovnkube-node-4wgzd                       8/8     Running   32         12d   172.21.6.26   worker-01-demo   <none>           <none>
# ovnkube-node-n5q6b                       8/8     Running   39         12d   172.21.6.23   master-01-demo   <none>           <none>

VAR_POD='ovnkube-node-4wgzd'

oc exec -it ${VAR_POD} -c ovn-controller -n openshift-ovn-kubernetes -- ovn-nbctl list load-balancer | grep 172.22.145.65 -B 8
# _uuid               : 38b40eee-be68-496f-8fa0-1728709b97bc
# external_ids        : {"k8s.ovn.org/kind"=Service, "k8s.ovn.org/owner"="nginx-ingress/nginxingress-sample-nginx-ingress-controller"}
# health_check        : []
# ip_port_mappings    : {}
# name                : "Service_nginx-ingress/nginxingress-sample-nginx-ingress-controller_TCP_cluster"
# options             : {event="false", hairpin_snat_ip="169.254.169.5 fd69::5", neighbor_responder=none, reject="true", skip_snat="false"}
# protocol            : tcp
# selection_fields    : []
# vips                : {"172.22.145.65:443"="10.133.0.21:443", "172.22.145.65:80"="10.133.0.21:80"}

oc get ep -A | grep 10.133.0.21
# nginx-ingress                                      nginxingress-sample-nginx-ingress-controller                10.133.0.21:443,10.133.0.21:80                                      6h55m


oc get pod -n nginx-ingress
# NAME                                                            READY   STATUS    RESTARTS   AGE
# nginx-ingress-operator-controller-manager-6d8cbd487d-4rp6m      2/2     Running   0          8h
# nginxingress-sample-nginx-ingress-controller-5ddd56f675-7g5k7   1/1     Running   0          7h2m


VAR_POD='nginxingress-sample-nginx-ingress-controller-5ddd56f675-7g5k7'

oc exec -it ${VAR_POD} -n nginx-ingress  -- ls /etc/nginx/conf.d
# llm-demo-ingress-demo-wzh.conf

oc exec -it ${VAR_POD} -n nginx-ingress  -- cat /etc/nginx/conf.d/llm-demo-ingress-demo-wzh.conf
# # configuration for llm-demo/ingress-demo-wzh
# upstream llm-demo-ingress-demo-wzh-nginx-demo.wzhlab.top-web-demo-8080 {zone llm-demo-ingress-demo-wzh-nginx-demo.wzhlab.top-web-demo-8080 256k;random two least_conn;
#         server 10.133.0.56:8080 max_fails=1 fail_timeout=10s max_conns=0;
# }

# server {
#         listen 80;listen [::]:80;

#         server_tokens on;

#         server_name nginx-demo.wzhlab.top;

#         set $resource_type "ingress";
#         set $resource_name "ingress-demo-wzh";
#         set $resource_namespace "llm-demo";
#         location / {
#                 set $service "web-demo";
#                 proxy_http_version 1.1;

#                 proxy_connect_timeout 60s;
#                 proxy_read_timeout 60s;
#                 proxy_send_timeout 60s;
#                 client_max_body_size 1m;
#                 proxy_set_header Host $host;
#                 proxy_set_header X-Real-IP $remote_addr;
#                 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
#                 proxy_set_header X-Forwarded-Host $host;
#                 proxy_set_header X-Forwarded-Port $server_port;
#                 proxy_set_header X-Forwarded-Proto $scheme;
#                 proxy_buffering on;
#                 proxy_pass http://llm-demo-ingress-demo-wzh-nginx-demo.wzhlab.top-web-demo-8080;
#         }

# }

oc get ep -A | grep 10.133.0.56
# llm-demo                                           web-demo                                                    10.133.0.56:8080                                                    55m

oc get pod -n llm-demo -o wide
# NAME                        READY   STATUS    RESTARTS   AGE   IP            NODE             NOMINATED NODE   READINESS GATES
# web-demo-755c9b6f47-xh8b8   1/1     Running   0          55m   10.133.0.56   worker-01-demo   <none>           <none>

```

# end